{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14988,"status":"ok","timestamp":1674715163119,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"K4eUNg6xBWOg","outputId":"2b79ee4b-8cb0-41d8-ecb4-103af895cd9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: piqa in /usr/local/lib/python3.8/dist-packages (1.2.2)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from piqa) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from piqa) (0.14.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->piqa) (4.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->piqa) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->piqa) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->piqa) (1.21.6)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->piqa) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->piqa) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->piqa) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->piqa) (2022.12.7)\n"]}],"source":["!pip install torchmetrics\n","!pip install piqa\n","from piqa import MS_SSIM\n","from scipy.io import loadmat\n","from sklearn.model_selection import train_test_split\n","from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n","import os\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torchvision import transforms\n","import cv2\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from torchvision.io import read_image\n","from typing import Tuple,List,Callable"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1391,"status":"ok","timestamp":1674715164494,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"kQ9o8raOEhJq","outputId":"d7b02710-cd95-4b1a-feb3-d25ccc70807f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1674715164496,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"f0oM630oIUaY","outputId":"bd9f0dc2-bbbb-4f3e-cba8-d7dd71dd7148"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["# use CUDA processors if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1674715164497,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"2L12D20XB6i7"},"outputs":[],"source":["def process_mat(directory: str, train: bool, test_files: list) -> Tuple[torch.Tensor, int, list, list]:\n","    # prepare feature data and image paths\n","    image_paths = []\n","    digits = []\n","    raw_data = None\n","    clean = f'{directory}/clean_split'\n","    for filename in os.listdir(clean): #iterate through the files in directory\n","        file = os.path.join(clean, filename)\n","        # checking if it is a file\n","        if os.path.isfile(file):\n","            if train:\n","                id = 'rain.pt'\n","            else:\n","                id = 'test.pt'\n","            if (filename[-7:] == id):\n","                if (id ==  'rain.pt') or (id == 'test.pt' and ((test_files == None) or (filename in test_files))):\n","                    print(filename)\n","                    data = torch.load(file)\n","                    features = data[0]\n","                    labels = data[1]\n","                    if raw_data is None:\n","                        raw_data = features\n","                    else:\n","                        try:\n","                            raw_data = np.append(raw_data, features, axis=0)\n","                        except:\n","                            print(f\"IGNORED: {filename}\")\n","                            continue\n","                    for i, y in enumerate(labels):\n","                        if not os.path.isfile(y[0]):\n","                            print(f\"INGORED IMAGE: {y[0]}\")\n","                            index = i - len(labels)\n","                            print(labels[index][0]==y[0])\n","                            print(raw_data.shape)\n","                            raw_data = np.delete(raw_data, index, 0)\n","                            continue\n","                        else:\n","                            image_paths.append(y[0])\n","                            digits.append(y[1])\n","                else:\n","                    continue\n","            else:\n","                continue\n","        else:\n","            raise Exception(\"this is not a file\")\n","    print(type(raw_data))\n","    raw_data = torch.tensor(raw_data.astype(np.float32)).cuda()\n","    num_features = raw_data.shape[1]\n","    print(len(image_paths))\n","    return raw_data, num_features, image_paths, digits"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1674715164498,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"8msj0S4gOEr8"},"outputs":[],"source":["# define data transformations\n","def feature_transform(x: torch.Tensor):\n","    # standardizes the features of a given data point\n","    mean = x.mean()\n","    std = x.std()\n","    return x.sub(mean).div(std)\n","\n","def img_label_transform(y: str):\n","    # transforms an image path to a usable tensor\n","    image = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    convert_tensor = A.Compose([A.ToFloat(max_value=255), ToTensorV2()])\n","    try:\n","        thingy = convert_tensor(image=image)['image']\n","    except Exception as e:\n","        print(e)\n","        raise Exception(f\"Image not found: {y}\")\n","    return thingy.cuda()\n","\n","def digit_label_transform(y: str):\n","    return int(y)\n","\n","# create train and test Datasets and DataLoaders\n","class ReconstructionData(Dataset):\n","    def __init__(self, raw_features: torch.Tensor, labels: list, feature_transform, label_transform: None):\n","        self.features = raw_features\n","        self.labels = labels\n","        self.feature_transform = feature_transform\n","        self.label_transform = label_transform\n","\n","\n","    def __len__(self):\n","        return len(self.features)\n","    \n","    def __getitem__(self, idx):\n","        data = self.feature_transform(self.features[idx])\n","        label = self.label_transform(self.labels[idx])\n","        return data, label\n","\n","\n","def prep_data(train_features: torch.Tensor, train_labels: list, test_features: torch.Tensor, test_labels: list, label_transform, batch_size:int) -> Tuple[DataLoader, DataLoader]:\n","    # create train and test dataloaders\n","    train_data = ReconstructionData(train_features, train_labels, feature_transform, label_transform)\n","    test_data = ReconstructionData(test_features, test_labels, feature_transform, label_transform)\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","    return train_dataloader,test_dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":196,"status":"ok","timestamp":1674715164678,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"Hfz3D2xPUCxV"},"outputs":[],"source":["class ImgReconstructNN(nn.Module):\n","    def __init__(self, num_features:int):\n","        super(ImgReconstructNN, self).__init__()\n","        self.linear_relu_deconv_stack = nn.Sequential(\n","            nn.Linear(num_features, 512),\n","            nn.PReLU(),\n","            nn.Linear(512, 2048),\n","            nn.PReLU(),\n","            nn.Linear(2048, 28*28),\n","            nn.Sigmoid(),\n","            nn.Unflatten(1, (1, 28, 28))\n","        )\n","    def forward(self, x):\n","        logits = self.linear_relu_deconv_stack(x)\n","        return logits\n","\n","class ClassifyNN(nn.Module):\n","    # INCOMPLETE\n","    # TO DO\n","    def __init__(self, num_features:int):\n","        super(ImgReconstructNN, self).__init__()\n","        self.linear_relu_deconv_stack = nn.Sequential(\n","            nn.Linear(num_features, 512),\n","            nn.PReLU(),\n","            nn.Linear(512, 2048),\n","            nn.PReLU(),\n","            nn.Linear(2048, 28*28),\n","            nn.Sigmoid(),\n","            nn.Unflatten(1, (1, 28, 28))\n","        )\n","    def forward(self, x):\n","        logits = self.linear_relu_deconv_stack(x)\n","        return logits"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674715164678,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"toUe8npd9gRT"},"outputs":[],"source":["def create_model(num_features:int) -> nn.Module:\n","  model = ImgReconstructNN(num_features).to(device)\n","  print(model)\n","  return model"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674715164679,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"UP9-2Ndy_wQh"},"outputs":[],"source":["# Training loop\n","def train_loop(dataloader: DataLoader, model: nn.Module, loss_fn, optimizer, print_loss: bool, loss_list: list) -> list:\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    train_loss = 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        train_loss += loss\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    train_loss /= num_batches\n","    loss_list.append(train_loss)\n","    if print_loss:  \n","        print(f\"Avg batch loss: {train_loss:>8f}\")\n","    return loss_list\n","\n","def test_loop(dataloader, model, loss_fn):\n","    print(\"Running Test Loop\")\n","    num_batches = len(dataloader)\n","    test_loss = 0\n","    test_psnr = 0\n","    test_ssim = 0\n","    psnr = PeakSignalNoiseRatio().to(device)\n","    ssim = StructuralSimilarityIndexMeasure().to(device)\n","\n","    with torch.no_grad():\n","        for batch, (X, y) in enumerate(dataloader):       \n","            print(f\"batch: {batch+1}\")     \n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            test_ssim += ssim(pred, y).item()\n","            test_psnr += psnr(pred, y).item()\n","\n","            # display 1 original and predicted image from each batch\n","            transform = transforms.ToPILImage()\n","            orig_data = y[0]\n","            orig_img = transform(orig_data)\n","            pred_data = pred[0]\n","            pred_img = transform(pred_data)\n","            print(\"original:\")\n","            display(orig_img)\n","            print(\"predicted:\")\n","            display(pred_img)\n","            print()\n","\n","    test_loss /= num_batches\n","    test_psnr /= num_batches\n","    test_ssim /= num_batches\n","    print(f\"Avg batch loss: {test_loss:>8f}\")\n","    print(f\"Avg batch PSNR: {test_psnr:>8f}\")\n","    print(f\"Avg batch SSIM: {test_ssim:>8f}\")\n","    return model, test_loss, test_psnr, test_ssim"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674715164680,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"ziE8bKqrFm8d"},"outputs":[],"source":["def train_model(train_dataloader, model, loss_fn, optimizer, epochs):\n","  losses = []\n","  for t in range(epochs):\n","      print_loss = False\n","      if (t % 8 == 7) or (t==0):\n","        print_loss = True\n","        print(\"-------------------------------\")\n","        print(f\"Epoch {t+1}\")\n","      losses = train_loop(train_dataloader, model, loss_fn, optimizer, print_loss, losses)\n","  print(\"Done!\")\n","  return losses"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1674715164681,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"XYJnlEsNnZv6"},"outputs":[],"source":["# Validation Results:\n","#  32-epoch loss: 0.014299\n","#  48-epoch loss: 0.013660 \n","#  64-epoch loss: 0.013298\n","#  80-epoch loss: 0.013655 \n","#  96-epoch loss: 0.013975\n","# 128-epoch loss: 0.014216\n","# 192-epoch loss: 0.015130"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674715164681,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"bS6RKxLH7AZs"},"outputs":[],"source":["def plot_loss(losses: list) -> None:\n","    losses = np.array(torch.tensor(losses).cpu())\n","    plt.plot(losses, color='red')\n","    plt.ylabel('Average Batch Loss') #set the label for y axis\n","    plt.xlabel('Epoch') #set the label for x-axis\n","    plt.title(\"Loss over Training Epochs\") #set the title of the graph\n","    plt.show() #display the graph"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1674715164682,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"t9xN4GyozNxw"},"outputs":[],"source":["def run(directory: str, test_files, batch_size, loss_fn, learning_rate, epochs: int):\n","    print(\"PART 1\")\n","    train_data, num_features, train_image_paths, _ = process_mat(directory, True, None)\n","    print(\"PART 2\")\n","    test_data, num_features, test_image_paths, _ = process_mat(directory, False, None)\n","    print(\"PART 3\")\n","    train_dataloader, test_dataloader = prep_data(train_data, train_image_paths, test_data, test_image_paths, img_label_transform, batch_size)\n","    print(\"PART 4\")\n","    model = create_model(num_features)\n","    print(\"PART 5\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    print(\"PART 6\")\n","    train_loss = train_model(train_dataloader, model, loss_fn, optimizer, epochs)\n","    print(\"PART 7\")\n","    plot_loss(train_loss)\n","    print(\"PART 8\")\n","    model, test_loss, test_psnr, test_ssim = test_loop(test_dataloader, model, loss_fn)\n","    return model, train_loss, test_loss, test_psnr, test_ssim"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1862,"status":"ok","timestamp":1674715166535,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"pSxam34QCxnm"},"outputs":[],"source":["l1 = nn.L1Loss()\n","class L1_SSIM_loss(MS_SSIM):\n","    def forward(self, x, y):\n","        return (0.5 * (1. - super().forward(x, y))) + (0.5 * l1.forward(x, y))\n","\n","criterion = L1_SSIM_loss(window_size=2, n_channels=1).cuda()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1674715166537,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"_WWF7uFUnAkj"},"outputs":[],"source":["# prepare directories\n","main_dir = '/content/drive/MyDrive/superresolution/nonlinear_classification'\n","data_dir = f'{main_dir}/data/features/EXP_by_crystal'\n","image_dir = f'{main_dir}/data/digit_image'\n","\n","# hyper-parameters:\n","batch_size = 50\n","learning_rate = 1e-3\n","epochs = 64\n","loss_fn = criterion # L1_SSIM_loss(window_size=4.3, n_channels=1).cuda()\n","\n","# sample_dir = f'{data_dir}/original_EXP_data/with_noise/ChangeCrystalPosition_DATA/shiftCrystal40mm_SNR17(s10)_1-200samples_40LG_10loop_Oct12'\n","# run(sample_dir, test_size, batch_size, loss_fn, learning_rate, epochs)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1674715166538,"user":{"displayName":"Matthew Thomas","userId":"08635113081893331323"},"user_tz":300},"id":"DIzJFdWmOuwR"},"outputs":[],"source":["# 64 Epoch piqa\n","# Avg batch loss: 0.084998\n","# Avg batch PSNR: 15.341266\n","# Avg batch SSIM: 0.573755\n","\n","# 128 Epoch piqa\n","# Avg batch loss: 0.063156\n","# Avg batch PSNR: 16.070961\n","# Avg batch SSIM: 0.636266\n","\n","# 256 epoch 1/2 SSIM 1/2 MAE\n","# Avg batch loss: 0.057746\n","# Avg batch PSNR: 17.995046\n","# Avg batch SSIM: 0.764595"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoL8WO6NtKrD","outputId":"569704e5-c226-4658-c3a8-fe6eab752548"},"outputs":[{"name":"stdout","output_type":"stream","text":["PART 1\n","1-200sample_40LG_area40_amp100_pixel400_Aug9_10loop_10cluster_train.pt\n","200-400sample_40LG_area40_amp100_pixel400_Aug11_10loop_10cluster_train.pt\n","200-400sample_40LG_area40_amp100_pixel400_Aug28_10loop_10cluster_train.pt\n","IGNORED: 200-400sample_40LG_area40_amp100_pixel400_Aug28_10loop_10cluster_train.pt\n","200sample_40LG_area40_amp200_set3_train.pt\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8983.png\n","True\n","(4800, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8998.png\n","True\n","(4799, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8988.png\n","True\n","(4798, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8973.png\n","True\n","(4797, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8993.png\n","True\n","(4796, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8978.png\n","True\n","(4795, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8968.png\n","True\n","(4794, 40)\n","400-600sample_40LG_area40_amp100_pixel400_Aug16_10loop_10cluster_train.pt\n","600sample_40LG_area40_amp200_pixel200_train.pt\n","600sample_40LG_area40_amp200_pixel400_train.pt\n","200samples_40LG_10loop_frist200_July23_train.pt\n","200samples_40LG_10loop_frist200_July31_train.pt\n","200samples_40LG_10loop_sample400-600_Aug1_train.pt\n","200samples_40LG_set3_10loop_July17_train.pt\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8998.png\n","True\n","(22873, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8968.png\n","True\n","(22872, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8978.png\n","True\n","(22871, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8988.png\n","True\n","(22870, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8973.png\n","True\n","(22869, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8993.png\n","True\n","(22868, 40)\n","INGORED IMAGE: /content/drive/MyDrive/superresolution/nonlinear_classification/data/digit_image/9/image8983.png\n","True\n","(22867, 40)\n","600sample_40LG_area40_amp200_pixel400_make_up_train.pt\n","<class 'numpy.ndarray'>\n","27666\n","PART 2\n","1-200sample_40LG_area40_amp100_pixel400_Aug9_10loop_10cluster_test.pt\n","200-400sample_40LG_area40_amp100_pixel400_Aug11_10loop_10cluster_test.pt\n","200-400sample_40LG_area40_amp100_pixel400_Aug28_10loop_10cluster_test.pt\n","IGNORED: 200-400sample_40LG_area40_amp100_pixel400_Aug28_10loop_10cluster_test.pt\n","200sample_40LG_area40_amp200_set3_test.pt\n","400-600sample_40LG_area40_amp100_pixel400_Aug16_10loop_10cluster_test.pt\n","600sample_40LG_area40_amp200_pixel200_test.pt\n","600sample_40LG_area40_amp200_pixel400_test.pt\n","200samples_40LG_10loop_frist200_July23_test.pt\n","200samples_40LG_10loop_frist200_July31_test.pt\n","200samples_40LG_10loop_sample400-600_Aug1_test.pt\n","200samples_40LG_set3_10loop_July17_test.pt\n","600sample_40LG_area40_amp200_pixel400_make_up_test.pt\n","<class 'numpy.ndarray'>\n","6920\n","PART 3\n","PART 4\n","ImgReconstructNN(\n","  (linear_relu_deconv_stack): Sequential(\n","    (0): Linear(in_features=40, out_features=512, bias=True)\n","    (1): PReLU(num_parameters=1)\n","    (2): Linear(in_features=512, out_features=2048, bias=True)\n","    (3): PReLU(num_parameters=1)\n","    (4): Linear(in_features=2048, out_features=784, bias=True)\n","    (5): Sigmoid()\n","    (6): Unflatten(dim=1, unflattened_size=(1, 28, 28))\n","  )\n",")\n","PART 5\n","PART 6\n","-------------------------------\n","Epoch 1\n"]}],"source":["sample_dir = f'{data_dir}/1f'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mL_QUtdmZ74X","outputId":"bb66e8e9-bb21-4eef-e6b5-0fa9c1fb728b"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["PART 1\n","shiftCystal_0.8f_200-400_40LG_10loop_Aug23_train.pt\n","shiftCystal_0.8f_200samples_40LG_10loop_Aug20_train.pt\n","shiftCystal_0.8f_400-600_40LG_10loop_Aug25_train.pt\n","<class 'numpy.ndarray'>\n","4800\n","PART 2\n","shiftCystal_0.8f_200-400_40LG_10loop_Aug23_test.pt\n","shiftCystal_0.8f_200samples_40LG_10loop_Aug20_test.pt\n","shiftCystal_0.8f_400-600_40LG_10loop_Aug25_test.pt\n","<class 'numpy.ndarray'>\n","1200\n","PART 3\n","PART 4\n","ImgReconstructNN(\n","  (linear_relu_deconv_stack): Sequential(\n","    (0): Linear(in_features=40, out_features=512, bias=True)\n","    (1): PReLU(num_parameters=1)\n","    (2): Linear(in_features=512, out_features=2048, bias=True)\n","    (3): PReLU(num_parameters=1)\n","    (4): Linear(in_features=2048, out_features=784, bias=True)\n","    (5): Sigmoid()\n","    (6): Unflatten(dim=1, unflattened_size=(1, 28, 28))\n","  )\n",")\n","PART 5\n","PART 6\n","-------------------------------\n","Epoch 1\n"]}],"source":["sample_dir = f'{data_dir}/Crystal0.8f'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iEjGJOjtKfM"},"outputs":[],"source":["sample_dir = f'{data_dir}/Crystal27mm'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iZlRrV0tKT_"},"outputs":[],"source":["sample_dir = f'{data_dir}/Crystal40mm'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1p4QsmZXVx6-M1JptQxBBaa3x_lSbddyl","timestamp":1674689318538},{"file_id":"1iA62ONQYbiHntHev9VWWLLrYbCHgLEO-","timestamp":1663905395512},{"file_id":"1EaCPIBB_2YmWIn_tf-F_wAK8prTLo4Pn","timestamp":1661800287882},{"file_id":"1x3sg-Py8k1PUF2CJtwLIg_kzylSg66Yp","timestamp":1660887090026},{"file_id":"14sq-gl18hnwAu0kO5Mjf3Eu1T8D_zykL","timestamp":1660874710529}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}