{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26505,"status":"ok","timestamp":1680287907526,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"},"user_tz":240},"id":"K4eUNg6xBWOg","outputId":"32550ce2-9005-48e0-83bd-7b08700baf06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.13.1+cu116)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting piqa\n","  Downloading piqa-1.2.2-py3-none-any.whl (32 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from piqa) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from piqa) (0.14.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->piqa) (4.5.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.9.0->piqa) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.9.0->piqa) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.9.0->piqa) (1.22.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->piqa) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->piqa) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->piqa) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.9.0->piqa) (2022.12.7)\n","Installing collected packages: piqa\n","Successfully installed piqa-1.2.2\n"]}],"source":["!pip install torchmetrics\n","!pip install piqa\n","from piqa import MS_SSIM\n","from scipy.io import loadmat\n","from sklearn.model_selection import train_test_split\n","from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n","import os\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torchvision import transforms\n","import cv2\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from torchvision.io import read_image\n","from typing import Tuple,List,Callable"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74007,"status":"ok","timestamp":1680287981521,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"},"user_tz":240},"id":"kQ9o8raOEhJq","outputId":"b3add20f-ac8e-42b1-8cce-54f64351a7ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1680287981523,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"},"user_tz":240},"id":"f0oM630oIUaY","outputId":"a5913e84-8bca-4548-8570-3b073e960f17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["# use CUDA processors if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2L12D20XB6i7","executionInfo":{"status":"ok","timestamp":1680287981525,"user_tz":240,"elapsed":105,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["def process_mat(directory: str, train: bool, test_files: list) -> Tuple[torch.Tensor, int, list, list]:\n","    # prepare feature data and image paths\n","    image_paths = []\n","    digits = []\n","    raw_data = None\n","    clean = f'{directory}/clean_split'\n","    num_features = 40\n","    for filename in os.listdir(clean): #iterate through the files in directory\n","        file = os.path.join(clean, filename)\n","        # checking if it is a file\n","        if os.path.isfile(file):\n","            if train:\n","                id = 'rain.pt'\n","            else:\n","                id = 'test.pt'\n","            if (filename[-7:] == id):\n","                if (id ==  'rain.pt') or (id == 'test.pt' and ((test_files == None) or (filename in test_files))):\n","                    data = torch.load(file)\n","                    features = data[0]\n","                    labels = data[1]\n","                    if (features.shape[1] == num_features):\n","                        if raw_data is None:\n","                            raw_data = features\n","                        else:\n","                            raw_data = np.append(raw_data, features, axis=0)\n","                    else:\n","                        print(f\"IGNORED: {filename}\")\n","                        continue\n","                    for i, y in enumerate(labels):\n","                        if not os.path.isfile(y[0]):\n","                            print(f\"INGORED IMAGE: {y[0]}\")\n","                            index = i - len(labels)\n","                            print(labels[index][0]==y[0])\n","                            print(raw_data.shape)\n","                            raw_data = np.delete(raw_data, index, 0)\n","                            continue\n","                        else:\n","                            image_paths.append(y[0])\n","                            digits.append(y[1])\n","                else:\n","                    continue\n","            else:\n","                continue\n","        else:\n","            raise Exception(\"this is not a file\")\n","    print(type(raw_data))\n","    raw_data = torch.tensor(raw_data.astype(np.float32)).cuda()\n","    print(len(image_paths))\n","    return raw_data, num_features, image_paths, digits"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"8msj0S4gOEr8","executionInfo":{"status":"ok","timestamp":1680287981527,"user_tz":240,"elapsed":101,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["# define data transformations\n","def feature_transform(x: torch.Tensor):\n","    # standardizes the features of a given data point\n","    mean = x.mean()\n","    std = x.std()\n","    return x.sub(mean).div(std)\n","\n","def img_label_transform(y: str):\n","    # transforms an image path to a usable tensor\n","    image = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","    convert_tensor = A.Compose([A.ToFloat(max_value=255), ToTensorV2()])\n","    try:\n","        thingy = convert_tensor(image=image)['image']\n","    except Exception as e:\n","        print(e)\n","        raise Exception(f\"Image not found: {y}\")\n","    return thingy.cuda()\n","\n","def digit_label_transform(y: str):\n","    return int(y)\n","\n","# create train and test Datasets and DataLoaders\n","class ReconstructionData(Dataset):\n","    def __init__(self, raw_features: torch.Tensor, labels: list, feature_transform, label_transform: None):\n","        self.features = raw_features\n","        self.labels = labels\n","        self.feature_transform = feature_transform\n","        self.label_transform = label_transform\n","\n","\n","    def __len__(self):\n","        return len(self.features)\n","    \n","    def __getitem__(self, idx):\n","        data = self.feature_transform(self.features[idx])\n","        label = self.label_transform(self.labels[idx])\n","        return data, label\n","\n","\n","def prep_data(train_features: torch.Tensor, train_labels: list, test_features: torch.Tensor, test_labels: list, label_transform, batch_size:int) -> Tuple[DataLoader, DataLoader]:\n","    # create train and test dataloaders\n","    train_data = ReconstructionData(train_features, train_labels, feature_transform, label_transform)\n","    test_data = ReconstructionData(test_features, test_labels, feature_transform, label_transform)\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","    return train_dataloader,test_dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Hfz3D2xPUCxV","executionInfo":{"status":"ok","timestamp":1680287981528,"user_tz":240,"elapsed":97,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["class ImgReconstructNN(nn.Module):\n","    def __init__(self, num_features:int):\n","        super(ImgReconstructNN, self).__init__()\n","        self.linear_relu_deconv_stack = nn.Sequential(\n","            nn.Linear(num_features, 512),\n","            nn.PReLU(),\n","            nn.Linear(512, 2048),\n","            nn.PReLU(),\n","            nn.Linear(2048, 28*28),\n","            nn.Sigmoid(),\n","            nn.Unflatten(1, (1, 28, 28))\n","        )\n","    def forward(self, x):\n","        logits = self.linear_relu_deconv_stack(x)\n","        return logits\n","\n","class ClassifyNN(nn.Module):\n","    # INCOMPLETE\n","    # TO DO\n","    def __init__(self, num_features:int):\n","        super(ImgReconstructNN, self).__init__()\n","        self.linear_relu_deconv_stack = nn.Sequential(\n","            nn.Linear(num_features, 512),\n","            nn.PReLU(),\n","            nn.Linear(512, 2048),\n","            nn.PReLU(),\n","            nn.Linear(2048, 28*28),\n","            nn.Sigmoid(),\n","            nn.Unflatten(1, (1, 28, 28))\n","        )\n","    def forward(self, x):\n","        logits = self.linear_relu_deconv_stack(x)\n","        return logits"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"toUe8npd9gRT","executionInfo":{"status":"ok","timestamp":1680287981530,"user_tz":240,"elapsed":94,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["def create_model(num_features:int) -> nn.Module:\n","  model = ImgReconstructNN(num_features).to(device)\n","  print(model)\n","  return model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"UP9-2Ndy_wQh","executionInfo":{"status":"ok","timestamp":1680287981533,"user_tz":240,"elapsed":93,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["# Training loop\n","def train_loop(dataloader: DataLoader, model: nn.Module, loss_fn, optimizer, print_loss: bool, loss_list: list) -> list:\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    train_loss = 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        train_loss += loss\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    train_loss /= num_batches\n","    loss_list.append(train_loss)\n","    if print_loss:  \n","        print(f\"Avg batch loss: {train_loss:>8f}\")\n","    return loss_list\n","\n","def test_loop(dataloader, model, loss_fn):\n","    print(\"Running Test Loop\")\n","    num_batches = len(dataloader)\n","    test_loss = 0\n","    test_psnr = 0\n","    test_ssim = 0\n","    psnr = PeakSignalNoiseRatio().to(device)\n","    ssim = StructuralSimilarityIndexMeasure().to(device)\n","\n","    with torch.no_grad():\n","        for batch, (X, y) in enumerate(dataloader):       \n","            print(f\"batch: {batch+1}\")\n","            probs = model(X)\n","            preds = torch.argmax(probs, dim=1)\n","            test_loss += loss_fn(preds, y).item()\n","            test_ssim += ssim(preds, y).item()\n","            test_psnr += psnr(preds, y).item()\n","\n","            # display 1 original and predicted image from each batch\n","            transform = transforms.ToPILImage()\n","            orig_data = y[0]\n","            orig_img = transform(orig_data)\n","            pred_data = pred[0]\n","            pred_img = transform(pred_data)\n","            print(\"original:\")\n","            display(orig_img)\n","            print(\"predicted:\")\n","            display(pred_img)\n","            print()\n","\n","    test_loss /= num_batches\n","    test_psnr /= num_batches\n","    test_ssim /= num_batches\n","    print(f\"Avg batch loss: {test_loss:>8f}\")\n","    print(f\"Avg batch PSNR: {test_psnr:>8f}\")\n","    print(f\"Avg batch SSIM: {test_ssim:>8f}\")\n","    return model, test_loss, test_psnr, test_ssim"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ziE8bKqrFm8d","executionInfo":{"status":"ok","timestamp":1680287981535,"user_tz":240,"elapsed":91,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["def train_model(train_dataloader, model, loss_fn, optimizer, epochs):\n","  losses = []\n","  for t in range(epochs):\n","      print_loss = False\n","      if (t % 8 == 7) or (t==0):\n","        print_loss = True\n","        print(\"-------------------------------\")\n","        print(f\"Epoch {t+1}\")\n","      losses = train_loop(train_dataloader, model, loss_fn, optimizer, print_loss, losses)\n","  print(\"Done!\")\n","  return losses"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"XYJnlEsNnZv6","executionInfo":{"status":"ok","timestamp":1680287981537,"user_tz":240,"elapsed":88,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["# Validation Results:\n","#  32-epoch loss: 0.014299\n","#  48-epoch loss: 0.013660 \n","#  64-epoch loss: 0.013298\n","#  80-epoch loss: 0.013655 \n","#  96-epoch loss: 0.013975\n","# 128-epoch loss: 0.014216\n","# 192-epoch loss: 0.015130"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bS6RKxLH7AZs","executionInfo":{"status":"ok","timestamp":1680287981538,"user_tz":240,"elapsed":85,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["def plot_loss(losses: list) -> None:\n","    losses = np.array(torch.tensor(losses).cpu())\n","    plt.plot(losses, color='red')\n","    plt.ylabel('Average Batch Loss') #set the label for y axis\n","    plt.xlabel('Epoch') #set the label for x-axis\n","    plt.title(\"Loss over Training Epochs\") #set the title of the graph\n","    plt.show() #display the graph"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"t9xN4GyozNxw","executionInfo":{"status":"ok","timestamp":1680287981540,"user_tz":240,"elapsed":85,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["def run(directory: str, test_files, batch_size, loss_fn, learning_rate, epochs: int):\n","    print(\"PART 1\")\n","    train_data, num_features, train_image_paths, _ = process_mat(directory, True, None)\n","    print(\"PART 2\")\n","    test_data, num_features, test_image_paths, _ = process_mat(directory, False, None)\n","    print(\"PART 3\")\n","    train_dataloader, test_dataloader = prep_data(train_data, train_image_paths, test_data, test_image_paths, img_label_transform, batch_size)\n","    print(\"PART 4\")\n","    model = create_model(num_features)\n","    print(\"PART 5\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    print(\"PART 6\")\n","    train_loss = train_model(train_dataloader, model, loss_fn, optimizer, epochs)\n","    print(\"PART 7\")\n","    plot_loss(train_loss)\n","    print(\"PART 8\")\n","    model, test_loss, test_psnr, test_ssim = test_loop(test_dataloader, model, loss_fn)\n","    return model, train_loss, test_loss, test_psnr, test_ssim"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pSxam34QCxnm","executionInfo":{"status":"ok","timestamp":1680287985661,"user_tz":240,"elapsed":4203,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["l1 = nn.L1Loss()\n","class L1_SSIM_loss(MS_SSIM):\n","    def forward(self, x, y):\n","        return (0.5 * (1. - super().forward(x, y))) + (0.5 * l1.forward(x, y))\n","\n","criterion = L1_SSIM_loss(window_size=2, n_channels=1).cuda()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"oTfnbdc6Za9t"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"_WWF7uFUnAkj","executionInfo":{"status":"ok","timestamp":1680287985663,"user_tz":240,"elapsed":69,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["# prepare directories\n","main_dir = '/content/drive/MyDrive/superresolution/nonlinear_classification'\n","data_dir = f'{main_dir}/data/features/SIM_by_crystal'\n","image_dir = f'{main_dir}/data/digit_image'\n","\n","# hyper-parameters:\n","batch_size = 50\n","learning_rate = 1e-3\n","epochs = 512\n","loss_fn = criterion # L1_SSIM_loss(window_size=4.3, n_channels=1).cuda()\n","\n","# sample_dir = f'{data_dir}/original_EXP_data/with_noise/ChangeCrystalPosition_DATA/shiftCrystal40mm_SNR17(s10)_1-200samples_40LG_10loop_Oct12'\n","# run(sample_dir, test_size, batch_size, loss_fn, learning_rate, epochs)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"DIzJFdWmOuwR","executionInfo":{"status":"ok","timestamp":1680287985665,"user_tz":240,"elapsed":61,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}}},"outputs":[],"source":["# 64 Epoch piqa\n","# Avg batch loss: 0.084998\n","# Avg batch PSNR: 15.341266\n","# Avg batch SSIM: 0.573755\n","\n","# 128 Epoch piqa\n","# Avg batch loss: 0.063156\n","# Avg batch PSNR: 16.070961\n","# Avg batch SSIM: 0.636266\n","\n","# 256 epoch 1/2 SSIM 1/2 MAE\n","# Avg batch loss: 0.057746\n","# Avg batch PSNR: 17.995046\n","# Avg batch SSIM: 0.764595"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":953},"id":"1iEjGJOjtKfM","executionInfo":{"status":"error","timestamp":1677085446976,"user_tz":300,"elapsed":2072261,"user":{"displayName":"Matthew Thomas","userId":"01391182395317566927"}},"outputId":"40f29133-5428-497e-9dd9-48745a991178"},"outputs":[{"output_type":"stream","name":"stdout","text":["PART 1\n","IGNORED: 1-200samples_105LG_N800_dx5.2_s10_sameSNR15_27mm_train.pt\n","IGNORED: 1-200samples_112LG_N800_dx5.2_s10_sameSNR10_27mm_train.pt\n","IGNORED: changeCrystalPosition_27mm_49HG_1-200sample_digit800_dx5.2_train.pt\n","<class 'numpy.ndarray'>\n","11200\n","PART 2\n","IGNORED: 1-200samples_105LG_N800_dx5.2_s10_sameSNR15_27mm_test.pt\n","IGNORED: 1-200samples_112LG_N800_dx5.2_s10_sameSNR10_27mm_test.pt\n","IGNORED: changeCrystalPosition_27mm_49HG_1-200sample_digit800_dx5.2_test.pt\n","<class 'numpy.ndarray'>\n","2800\n","PART 3\n","PART 4\n","ImgReconstructNN(\n","  (linear_relu_deconv_stack): Sequential(\n","    (0): Linear(in_features=40, out_features=512, bias=True)\n","    (1): PReLU(num_parameters=1)\n","    (2): Linear(in_features=512, out_features=2048, bias=True)\n","    (3): PReLU(num_parameters=1)\n","    (4): Linear(in_features=2048, out_features=784, bias=True)\n","    (5): Sigmoid()\n","    (6): Unflatten(dim=1, unflattened_size=(1, 28, 28))\n","  )\n",")\n","PART 5\n","PART 6\n","-------------------------------\n","Epoch 1\n","Avg batch loss: 0.226500\n","-------------------------------\n","Epoch 8\n","Avg batch loss: 0.180113\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-5af5368ee3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{data_dir}/27mm'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_psnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{sample_dir}/model.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{sample_dir}/train_loss.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-a30caefd3a3e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(directory, test_files, batch_size, loss_fn, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PART 6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PART 7\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-57fead3bd9a0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataloader, model, loss_fn, optimizer, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-702c1a29e8af>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, print_loss, loss_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-c715151153a4>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-c715151153a4>\u001b[0m in \u001b[0;36mimg_label_transform\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_label_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# transforms an image path to a usable tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mconvert_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToFloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["sample_dir = f'{data_dir}/27mm'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mL_QUtdmZ74X"},"outputs":[],"source":["sample_dir = f'{data_dir}/0.8f'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoL8WO6NtKrD"},"outputs":[],"source":["sample_dir = f'{data_dir}/1f'\n","model, train_loss, test_loss, test_psnr, test_ssim = run(sample_dir, None, batch_size, loss_fn, learning_rate, epochs)\n","filename = f'{sample_dir}/model.pt'\n","torch.save(model.state_dict(), filename)\n","filename = f'{sample_dir}/train_loss.pt'\n","torch.save(train_loss, filename)\n","filename = f'{sample_dir}/test_loss.pt'\n","torch.save(test_loss, filename)\n","filename = f'{sample_dir}/test_psnr.pt'\n","torch.save(test_psnr, filename)\n","filename = f'{sample_dir}/test_ssim.pt'\n","torch.save(test_ssim, filename)"]},{"cell_type":"code","source":["def test_run(directory: str, test_files, batch_size, loss_fn, learning_rate, epochs: int):\n","    train_data, num_features, train_image_paths, _ = process_mat(\n","        directory, True, test_files)\n","    test_data, num_features, test_image_paths, _ = process_mat(\n","        directory, False, test_files)\n","    _, test_dataloader = prep_data(\n","        train_data, train_image_paths, test_data, test_image_paths, img_label_transform, batch_size)\n","    model = create_model(num_features, False)\n","    filename = os.path.join(directory, 'model.pt')\n","    model.load_state_dict(torch.load(filename))\n","    model, test_loss, test_psnr, test_ssim = test_loop(\n","        test_dataloader, model, loss_fn, False)\n","    return model, test_loss, test_psnr, test_ssim"],"metadata":{"id":"pFjqRQwk9dlw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = {}\n","results['crystal_position'] = []\n","results['filename'] = []\n","results['test_loss'] = []\n","results['test_psnr'] = []\n","results['test_ssim'] = []\n","\n","load()\n","\n","for crystal in crystals:\n","    sample_dir = os.path.join(data_dir, crystal)\n","    sample_clean = os.path.join(sample_dir, 'clean_split')\n","    # iterate through the files in directory\n","    for filename in os.listdir(sample_clean):\n","        file = os.path.join(sample_clean, filename)\n","        # checking if it is a file\n","        if os.path.isfile(file):\n","            if (filename[-7:] == 'test.pt'):\n","                try:\n","                    model, test_loss, test_psnr, test_ssim = test_run(\n","                        sample_dir, [filename], batch_size, loss_fn, learning_rate, epochs)\n","                    results['crystal_position'].append(crystal)\n","                    results['filename'].append(filename)\n","                    results['test_loss'].append(test_loss)\n","                    results['test_psnr'].append(test_psnr)\n","                    results['test_ssim'].append(test_ssim)\n","                except:\n","                    continue\n","            else:\n","                continue\n","        else:\n","            print(file)\n","            raise Exception(\"this is not a file\")\n","\n","results = pd.DataFrame.from_dict(results)\n","filename = os.path.join(main_dir, 'data', 'sim_results.csv')\n","results.to_csv(filename, index=False)"],"metadata":{"id":"QlHVStrL5LuR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1iA62ONQYbiHntHev9VWWLLrYbCHgLEO-","timestamp":1663905395512},{"file_id":"1EaCPIBB_2YmWIn_tf-F_wAK8prTLo4Pn","timestamp":1661800287882},{"file_id":"1x3sg-Py8k1PUF2CJtwLIg_kzylSg66Yp","timestamp":1660887090026},{"file_id":"14sq-gl18hnwAu0kO5Mjf3Eu1T8D_zykL","timestamp":1660874710529}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}